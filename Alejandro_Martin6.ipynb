{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 06 – Topic Modeling con LDA\n",
        "\n",
        "En este notebook aplicamos técnicas de Topic Modeling usando Latent Dirichlet Allocation (LDA) para descubrir los temas principales que aparecen en las reviews de productos para bebés. El objetivo es identificar qué aspectos o temas discuten los usuarios en sus reseñas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargo el dataset de reviews ya procesado desde disco. Este dataset contiene las reviews limpias que preparamos en notebooks anteriores, con el texto preprocesado y las etiquetas de sentimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv(\"baby_reviews_small_clean.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para aplicar LDA necesito preparar los textos en un formato específico. Primero importo las librerías necesarias de Gensim para crear el diccionario y el corpus, y luego preparo los textos tokenizados. Cada review debe estar representada como una lista de palabras (tokens) para que LDA pueda trabajar con ella.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Convertir los textos limpios en listas de tokens\n",
        "texts = df['clean_text'].dropna().apply(lambda x: x.split()).tolist()\n",
        "\n",
        "print(f\"Total de documentos: {len(texts)}\")\n",
        "print(f\"Ejemplo de texto tokenizado: {texts[0][:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creo un diccionario que asigna un ID único a cada palabra única que aparece en el corpus. Este diccionario es necesario para convertir los textos en una representación numérica que LDA pueda procesar. También filtro palabras que aparecen en muy pocos documentos (menos de 2) o en demasiados (más del 50% de los documentos) porque no aportan información útil para identificar temas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear diccionario\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "\n",
        "# Filtrar palabras muy raras o muy comunes\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
        "\n",
        "print(f\"Tamaño del vocabulario después del filtrado: {len(dictionary)}\")\n",
        "print(f\"Primeras 10 palabras del diccionario: {list(dictionary.items())[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convierto los textos tokenizados en un formato de \"bag of words\" (bolsa de palabras) que LDA puede procesar. Cada documento se representa como una lista de tuplas (id_palabra, frecuencia), donde cada tupla indica cuántas veces aparece cada palabra en ese documento. Este formato es más eficiente para el algoritmo LDA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir textos a formato bag-of-words\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "print(f\"Tamaño del corpus: {len(corpus)}\")\n",
        "print(f\"Ejemplo de documento en formato bag-of-words (primeros 10 elementos): {corpus[0][:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entreno el modelo LDA con el corpus preparado. LDA es un modelo probabilístico que asume que cada documento es una mezcla de varios temas, y cada tema es una distribución sobre palabras. Configuro el modelo con 5 temas (num_topics=5) y uso parámetros estándar. El modelo aprenderá qué palabras son características de cada tema y qué temas están presentes en cada documento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelo LDA\n",
        "num_topics = 5\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=num_topics,\n",
        "    random_state=42,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "print(\"Modelo LDA entrenado exitosamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizo los temas descubiertos por el modelo. Para cada tema, muestro las 10 palabras más importantes (con mayor probabilidad de aparecer en ese tema). Esto me permite entender qué representa cada tema y darle un nombre descriptivo basado en las palabras clave que lo caracterizan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar los temas y sus palabras más importantes\n",
        "for idx, topic in lda_model.print_topics(-1, num_words=10):\n",
        "    print(f\"Tema {idx}:\")\n",
        "    print(topic)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculo la coherencia del modelo para evaluar qué tan bien están definidos los temas. La coherencia mide qué tan semánticamente similares son las palabras dentro de cada tema. Un valor más alto indica que las palabras de un tema están más relacionadas entre sí, lo que sugiere que el tema es más coherente y significativo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular coherencia del modelo\n",
        "coherence_model = CoherenceModel(\n",
        "    model=lda_model,\n",
        "    texts=texts,\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ")\n",
        "\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print(f\"Coherencia del modelo: {coherence_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pruebo diferentes números de temas (de 3 a 7) para encontrar el número óptimo. Para acelerar el proceso, uso menos iteraciones (passes=5) y un subconjunto del corpus para la búsqueda de hiperparámetros. Una vez encontrado el mejor número, entrenaré el modelo final con todos los datos y más iteraciones. El número de temas con mayor coherencia suele ser el mejor, ya que indica que los temas están bien definidos y son interpretables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar diferentes números de temas (optimizado para velocidad)\n",
        "# Usamos un subconjunto del corpus y menos iteraciones para la búsqueda\n",
        "from tqdm import tqdm\n",
        "\n",
        "coherence_scores = []\n",
        "num_topics_range = range(3, 8)  # Reducido de 3-8 a 3-7\n",
        "\n",
        "# Usar un subconjunto más pequeño para la búsqueda (más rápido)\n",
        "# Tomamos una muestra representativa del corpus\n",
        "sample_size = min(1000, len(corpus))\n",
        "corpus_sample = corpus[:sample_size]\n",
        "texts_sample = texts[:sample_size]\n",
        "\n",
        "print(f\"Buscando número óptimo de temas usando {sample_size} documentos...\")\n",
        "print(\"Esto tomará menos tiempo que usar todo el corpus.\\n\")\n",
        "\n",
        "for num_topics in tqdm(num_topics_range, desc=\"Probando temas\"):\n",
        "    model = LdaModel(\n",
        "        corpus=corpus_sample,  # Usar subconjunto para búsqueda\n",
        "        id2word=dictionary,\n",
        "        num_topics=num_topics,\n",
        "        random_state=42,\n",
        "        passes=5,  # Reducido de 10 a 5 para búsqueda rápida\n",
        "        alpha='auto',\n",
        "        iterations=50  # Limitar iteraciones por pass\n",
        "    )\n",
        "    \n",
        "    coherence_model = CoherenceModel(\n",
        "        model=model,\n",
        "        texts=texts_sample,  # Usar subconjunto para coherencia\n",
        "        dictionary=dictionary,\n",
        "        coherence='c_v'\n",
        "    )\n",
        "    \n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append(coherence_score)\n",
        "    print(f\"Temas: {num_topics}, Coherencia: {coherence_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizo los resultados de coherencia para cada número de temas probado. Esto me permite ver gráficamente qué número de temas produce el mejor modelo y tomar una decisión informada sobre cuántos temas usar en el modelo final.\n",
        "\n",
        "**¿Qué significa la coherencia?**\n",
        "La coherencia mide qué tan semánticamente relacionadas están las palabras dentro de cada tema. Un valor más alto indica que:\n",
        "- Las palabras de un tema aparecen juntas frecuentemente en los documentos\n",
        "- Los temas son más interpretables y tienen sentido semántico\n",
        "- El modelo está capturando mejor los temas reales en los datos\n",
        "\n",
        "**Interpretación de la gráfica:**\n",
        "- **Eje X**: Número de temas probados (de 3 a 7)\n",
        "- **Eje Y**: Coherencia del modelo (valores más altos = mejor)\n",
        "- **Punto más alto**: Indica el número óptimo de temas para este dataset\n",
        "\n",
        "Si la coherencia baja mucho al aumentar los temas, significa que estamos dividiendo demasiado los documentos y creando temas artificiales. Si sube, significa que más temas capturan mejor la estructura de los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(list(num_topics_range), coherence_scores, marker='o')\n",
        "plt.xlabel('Número de Temas')\n",
        "plt.ylabel('Coherencia')\n",
        "plt.title('Coherencia vs Número de Temas')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Encontrar el mejor número de temas\n",
        "best_num_topics = list(num_topics_range)[np.argmax(coherence_scores)]\n",
        "best_coherence = max(coherence_scores)\n",
        "print(f\"\\nMejor número de temas: {best_num_topics} (Coherencia: {best_coherence:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entreno el modelo final con el número óptimo de temas encontrado en el paso anterior, pero esta vez usando TODO el corpus y más iteraciones para obtener el mejor modelo posible. Este será el modelo que usaré para analizar los temas en las reviews y hacer predicciones sobre qué temas están presentes en cada documento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelo final con el mejor número de temas usando TODO el corpus\n",
        "print(f\"Entrenando modelo final con {best_num_topics} temas usando todo el corpus...\")\n",
        "print(\"Esto puede tardar unos minutos, pero será el modelo definitivo.\\n\")\n",
        "\n",
        "final_lda_model = LdaModel(\n",
        "    corpus=corpus,  # Ahora sí usamos todo el corpus\n",
        "    id2word=dictionary,\n",
        "    num_topics=best_num_topics,\n",
        "    random_state=42,\n",
        "    passes=10,  # Reducido de 15 a 10 (suficiente para buen modelo)\n",
        "    alpha='auto',\n",
        "    per_word_topics=True,\n",
        "    iterations=100  # Iteraciones por pass\n",
        ")\n",
        "\n",
        "# Mostrar los temas del modelo final\n",
        "print(\"Temas del modelo final:\")\n",
        "print(\"=\" * 60)\n",
        "for idx, topic in final_lda_model.print_topics(-1, num_words=10):\n",
        "    print(f\"\\nTema {idx}:\")\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para cada documento (review), obtengo la distribución de temas. Esto me dice qué porcentaje de cada tema está presente en cada review. Por ejemplo, una review podría ser 60% tema 0, 30% tema 1 y 10% tema 2. Esto permite entender qué aspectos discute cada usuario en su reseña.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener distribución de temas para cada documento\n",
        "doc_topics = []\n",
        "for doc_bow in corpus[:10]:  # Mostrar solo los primeros 10 documentos\n",
        "    topics = final_lda_model.get_document_topics(doc_bow)\n",
        "    doc_topics.append(topics)\n",
        "    print(f\"Documento {len(doc_topics)-1}:\")\n",
        "    for topic_id, prob in topics:\n",
        "        print(f\"  Tema {topic_id}: {prob:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creo una visualización interactiva usando pyLDAvis que permite explorar los temas de manera más intuitiva. Esta visualización muestra la relación entre temas y palabras, y permite ver qué documentos están más relacionados con cada tema. Es una herramienta muy útil para interpretar y validar los resultados del modelo LDA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear visualización interactiva\n",
        "try:\n",
        "    vis = gensimvis.prepare(final_lda_model, corpus, dictionary, sort_topics=False)\n",
        "    pyLDAvis.display(vis)\n",
        "except Exception as e:\n",
        "    print(f\"Error al crear visualización: {e}\")\n",
        "    print(\"Nota: pyLDAvis puede requerir configuración adicional en algunos entornos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardo el modelo entrenado para poder reutilizarlo más tarde sin tener que volver a entrenarlo. Esto es útil si quiero aplicar el modelo a nuevos documentos o hacer análisis adicionales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar modelo y diccionario\n",
        "final_lda_model.save(\"lda_baby_reviews.model\")\n",
        "dictionary.save(\"dictionary_baby_reviews.dict\")\n",
        "\n",
        "print(\"Modelo y diccionario guardados exitosamente\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
